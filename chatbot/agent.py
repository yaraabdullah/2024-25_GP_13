from langchain import hub
from langchain.agents import AgentExecutor, create_react_agent
from langchain.agents import AgentExecutor
from langchain_openai import ChatOpenAI
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.agents import Tool
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.memory import ConversationBufferWindowMemory
from dotenv import load_dotenv 
from langchain.document_loaders import TextLoader
from langchain.document_loaders import DirectoryLoader

# Load Environment Variables
load_dotenv(dotenv_path=".env",override=True)

# Initialize OpenAI Model (gpt-4)
openia_model = ChatOpenAI(
    model="gpt-4",
    temperature=0 #controls randomness in output

)

# - This memory object is used for the testing environment.
#   allowing us to evaluate the context-sensitive responses of the agent.
memory=ConversationBufferWindowMemory(memory_key="chat_history",return_messages=True,k=3) # We set a low k=3, to only keep the last 3 interactions in memory

# - This memory object is used in the deployed app.
# - It does not store interactions persistently because the app sends the
#   full history for each user as required. 
# - This separation ensures that users interactions do not conflict,
#   maintaining individual user sessions and personalized responses.
memory2=ConversationBufferWindowMemory(memory_key="chat_history",return_messages=True,k=0) 


#---------------------------------------------------------------------------------------------------------------------------------------------------

## RAG (Retrieval-Augmented Generation) Configuration :

# Directory where the database will be saved for persistence
persist_directory = 'db'

# Load text files
loader = DirectoryLoader('./RAG', glob="./*.txt", loader_cls=TextLoader)

# Load the documents using the DirectoryLoader
documents = loader.load()

# Initialize theOpenAI embedding 
embedding = OpenAIEmbeddings()

# Create a Chroma vector database from the loaded documents
vectordb = Chroma(persist_directory=persist_directory, 
                  embedding_function=embedding,
                   )

# persiste the db to disk
vectordb.persist()

# Create a retriever from the vector database
retriever = vectordb.as_retriever(search_kwargs={"k": 1}) # the retriever will return the top 1 most similar result (k=1)

# Create a RetrievalQA chain
qa_chain = RetrievalQA.from_chain_type(llm=openia_model, 
                                  chain_type="stuff", 
                                  retriever=retriever, 
                                  return_source_documents=False # no need for the source document
                                  )

# Create and Register RAG_tool Tool
RAG_tool= Tool(
name= "RAG_tool",
func= qa_chain.invoke,
description=("Use this tool to answer medical knowledge queries. you must answer JUST for (Stress, Depression and anxiety) mental ilness's. Keep responses concise")
)

tools=[RAG_tool]
tool_names=["RAG_tool"]

#---------------------------------------------------------------------------------------------------------------------------------------------------

#This section defines the prompt for the mental health support chatbot :
tem = """
Your name is SND Chatbot. You are a mental health support chatbot designed only for university students. Your role is to provide compassionate and professional responses to help students feel better, share their emotions, and talk about their day. Your primary focus is to encourage students to speak out more and provide support through positive and empathetic communication. When initializing a conversation, always ask about the student day, introduce yourself and mention that your role is to help.

instructions for use:
###
1. Scope of Support:

   - This chatbot is exclusively for mental health support for university students.
   - If the user asks questions requiring professional expertise (e.g., treatments, medications, or diagnoses), you MUST decline to provide an answer politely direct them to book an appointment with the professional doctors through SND.
   - Provide answers in concise and clear short text.
   - Do not answer any medical Question that is not covered by the tools, and redirect them to SND professionals.
   - Answer in Arabic or English based on the input.
   - Only answer medical Question and how to deal with them through the tool.

2. Use of Tools:
   - If the user asks for definitions, symptoms and advices ONLY use the 'RAG_tool' bound with the LLM.
   - For conversational purposes (e.g., discussing feelings, daily events), rely on the agent itself without using the RAG_tool tool.

3. Response Style:
   - Respond in a professional, empathetic, understanding and supportive manner.
   - Ask open-ended questions to encourage students to talk more about their emotions and experiences.

4. Out-of-Scope Questions:
   - If a user asks about topics outside mental health or university-related support, politely decline to provide an answer.
   - Dont give tips.
###
Examples for different use cases:

Example 1:
""
The user asks about definitions or symptoms, so the RAG_tool should be used for reliable information.
Question: "What is anxiety?"
Response: "Anxiety is a feeling of worry, nervousness, or unease about something with an uncertain outcome."
""

Example 2: 
""
The user asks about treatments or medications, so the chatbot should not provide any advice but instead guide the user to professional doctors while being empathetic and supportive.
Question: "How can stress be treated with medication?"
Response: "I understand how challenging it can be to manage stress, and I'm here to support you. While I can't provide advice on treatments or medication, I encourage you to reach out to one of the professional doctors available through SND. Theyâ€™ll be able to provide the personalized guidance and care you deserve. You're not alone, and help is always available."
""

Example 3:
""
The user wants to talk about their emotions.
User Input: "I've been feeling really overwhelmed lately with classes and everything."
Response:
"I'm really sorry to hear that you're feeling this way. It sounds like you're going through a lot, and that can be really tough. If you're comfortable, would you like to share more about what's been overwhelming you? and I'm here to listen."
""

Example 4:
""
The user asks a question outside the chatbot's scope.
Question: "What are the best universities for computer science?"
Response: "I'm sorry, I don't have the information to answer that question as my focus is on supporting students with their mental health. If there's anything you'd like to talk about regarding how you're feeling or what's on your mind, I'm here to listen and help in any way I can."
""

Example 5:
""
The user asks about managing stress, so the RAG_tool should be used for reliable information.
Question: "How can I manage stress?"
Response: "Stress can be managed through practices like regular physical activity.
""

\n\nTOOLS:\n------\n\nAssistant has access to the following tools:\n\n{tools}\n\nTo use a tool, please use the following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n```\n\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer: [your response here]\n```\n\nBegin!\n\nPrevious conversation history:\n{chat_history}\n\nNew input: {input}\n{agent_scratchpad}"""


prompt = hub.pull("hwchase17/react-chat") 
prompt.template = tem    


# Chatbot Agent and Executor Configurtion

# Agent Definition:
# - create_react_agent: Initializes the agent with the specified OpenAI model,
#   a custom prompt, and our tool to perform tasks.
agent = create_react_agent(openia_model, prompt=prompt, tools=tools )

# First Executor:
# - Used for testing purposes 
# - Memory: (ConversationBufferWindowMemory) is configured to retain only
#   the last 3 interactions to ensure concise context while testing.
agent_executor=AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=5, handle_parsing_errors=True , memory=memory) 

# Second Executor:
# - Deployed in SND app.
# - Memory: (ConversationBufferWindowMemory) is configured with `k=0`,
#   meaning it does not retain any memory persistently. The app dynamically sends
#   the full history per user as needed.
agent_executor2=AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=5, handle_parsing_errors=True , memory=memory2)
